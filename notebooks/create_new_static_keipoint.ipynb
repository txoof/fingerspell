{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b61ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8d6ee",
   "metadata": {},
   "source": [
    "## remove invalid letters from static keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4002d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'C', 'F', 'G', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T']\n",
      "[1, 2, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "keypoint_classifier_label = Path('../data/dataset/keypoint_classifier_label.csv')\n",
    "final_static_csv = Path('../data/dataset/ngt_static_keypoint.csv')\n",
    "additional_data_path = Path('../data/dataset/additional_data/')\n",
    "additional_data_glob = list(additional_data_path.glob('*.csv'))\n",
    "\n",
    "INVALID_LETTERS = list('BCFGKLMNOPQRST')\n",
    "invalid_indices = [ord(letter) - ord('A') for letter in INVALID_LETTERS]\n",
    "print(INVALID_LETTERS)\n",
    "print(invalid_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61e2d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (16976, 43)\n",
      "Label distribution before:\n",
      "0\n",
      "0     1898\n",
      "3     2275\n",
      "4     3840\n",
      "8     3592\n",
      "21    1227\n",
      "22    1965\n",
      "24    2179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cleaned shape: (16976, 43)\n",
      "Label distribution after:\n",
      "0\n",
      "0     1898\n",
      "3     2275\n",
      "4     3840\n",
      "8     3592\n",
      "21    1227\n",
      "22    1965\n",
      "24    2179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Clean existing data\n",
    "df = pd.read_csv(final_static_csv, header=None)\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Label distribution before:\\n{df[0].value_counts().sort_index()}\")\n",
    "\n",
    "df_cleaned = df[~df[0].isin(invalid_indices)]\n",
    "\n",
    "print(f\"\\nCleaned shape: {df_cleaned.shape}\")\n",
    "print(f\"Label distribution after:\\n{df_cleaned[0].value_counts().sort_index()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b34b29b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Step 2: Adding new data\n",
      "Expected columns: 43\n",
      "Found 1 CSV files to process\n",
      "\n",
      "Processing aaron_0123.csv...\n",
      "  Added 23668 rows\n",
      "\n",
      "==================================================\n",
      "Final Summary:\n",
      "  Rows added: 23668\n",
      "  Rows skipped: 0\n",
      "  Final shape: (40644, 43)\n",
      "  Final label distribution:\n",
      "0\n",
      "0     1898\n",
      "1     1592\n",
      "2     1610\n",
      "3     2275\n",
      "4     3840\n",
      "5     1666\n",
      "6     1722\n",
      "8     3592\n",
      "10    1898\n",
      "11    1668\n",
      "12    1664\n",
      "13    1580\n",
      "14    1675\n",
      "15    1682\n",
      "16    1707\n",
      "17    1818\n",
      "18    1710\n",
      "19    1676\n",
      "21    1227\n",
      "22    1965\n",
      "24    2179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved to ../data/dataset/ngt_static_keypoint.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Add new data from additional files\n",
    "expected_cols = df_cleaned.shape[1]\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Step 2: Adding new data\")\n",
    "print(f\"Expected columns: {expected_cols}\")\n",
    "print(f\"Found {len(additional_data_glob)} CSV files to process\")\n",
    "\n",
    "rows_added = 0\n",
    "rows_skipped = 0\n",
    "\n",
    "for csv_path in additional_data_glob:\n",
    "    print(f\"\\nProcessing {csv_path.name}...\")\n",
    "    df_new = pd.read_csv(csv_path, header=None)\n",
    "    \n",
    "    if df_new.shape[1] != expected_cols:\n",
    "        print(f\"  WARNING: Column mismatch! Expected {expected_cols}, got {df_new.shape[1]}\")\n",
    "        print(f\"  Skipping all {df_new.shape[0]} rows\")\n",
    "        rows_skipped += df_new.shape[0]\n",
    "        continue\n",
    "    \n",
    "    df_cleaned = pd.concat([df_cleaned, df_new], ignore_index=True)\n",
    "    rows_added += df_new.shape[0]\n",
    "    print(f\"  Added {df_new.shape[0]} rows\")\n",
    "\n",
    "# Step 3: Save final result\n",
    "df_cleaned.to_csv(final_static_csv, header=False, index=False)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Final Summary:\")\n",
    "print(f\"  Rows added: {rows_added}\")\n",
    "print(f\"  Rows skipped: {rows_skipped}\")\n",
    "print(f\"  Final shape: {df_cleaned.shape}\")\n",
    "print(f\"  Final label distribution:\\n{df_cleaned[0].value_counts().sort_index()}\")\n",
    "print(f\"\\nSaved to {final_static_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24f6e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerspell-venv-af5b43d44a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
