{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f63ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import copy\n",
    "import itertools\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43bc232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_landmark_list(image, landmarks):\n",
    "    \"\"\"Extract landmark coordinates.\"\"\"\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_point = []\n",
    "    for landmark in landmarks.landmark:\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "    return landmark_point\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    \"\"\"Normalize landmarks to relative coordinates.\"\"\"\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "    \n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = temp_landmark_list[0][0], temp_landmark_list[0][1]\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "    \n",
    "    # Flatten\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "    \n",
    "    # Normalization\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "    temp_landmark_list = list(map(lambda n: n / max_value, temp_landmark_list))\n",
    "    \n",
    "    return temp_landmark_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2095a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_remaining_letters(image, collection_counts, target):\n",
    "    \"\"\"Draw list of letters that still need collection at bottom of screen.\"\"\"\n",
    "    y_start = image.shape[0] - 100  # Bottom of screen\n",
    "    cv.rectangle(image, (10, y_start), (image.shape[1] - 10, image.shape[0] - 10), (0, 0, 0), -1)\n",
    "    \n",
    "    text = \"Remaining: \"\n",
    "    for letter in STATIC_LETTERS:\n",
    "        if collection_counts[letter] < target:\n",
    "            text += f\"{letter}({collection_counts[letter]}) \"\n",
    "    \n",
    "    cv.putText(image, text, (20, y_start + 30),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceed348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, landmark_point):\n",
    "    \"\"\"Draw hand skeleton from original app.py\"\"\"\n",
    "    if len(landmark_point) > 0:\n",
    "        # Thumb\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]), (255, 255, 255), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]), (255, 255, 255), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]), (255, 255, 255), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]), (255, 255, 255), 2)\n",
    "\n",
    "        # Pinky\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]), (255, 255, 255), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]), (255, 255, 255), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9201b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_collection_info(image, letter, collected, target, is_paused):\n",
    "    \"\"\"Draw collection progress at top.\"\"\"\n",
    "    cv.rectangle(image, (10, 10), (400, 150), (0, 0, 0), -1)\n",
    "    \n",
    "    if letter:\n",
    "        cv.putText(image, f\"Letter: {letter}\", (20, 40),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        cv.putText(image, f\"Captured: {collected}/{target}\", (20, 75),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        pct = (collected / target * 100) if target > 0 else 0\n",
    "        color = (0, 255, 0) if pct >= 100 else (255, 255, 255)\n",
    "        cv.putText(image, f\"{pct:.1f}%\", (20, 105),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        # Pause status\n",
    "        pause_text = \"PAUSED - Press SPACE\" if is_paused else \"Press SPACE to pause\"\n",
    "        pause_color = (0, 165, 255) if is_paused else (200, 200, 200)\n",
    "        cv.putText(image, pause_text, (20, 135),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, pause_color, 1)\n",
    "    else:\n",
    "        cv.putText(image, \"Press letter key\", (20, 50),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv.putText(image, \"to start collecting\", (20, 85),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv.putText(image, \"ESC to quit\", (20, 120),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 1)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c28248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_collection(output_csv):\n",
    "    \"\"\"Main collection loop.\"\"\"\n",
    "    \n",
    "    # Setup camera\n",
    "    cap = cv.VideoCapture(0)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, 960)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, 540)\n",
    "    \n",
    "    # Setup MediaPipe\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=0.7,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    \n",
    "    # Track collection per letter\n",
    "    collection_counts = {letter: 0 for letter in STATIC_LETTERS}\n",
    "    current_letter = None\n",
    "    is_paused = False\n",
    "    \n",
    "    print(\"Collection started. Press letter keys (A-Z) to collect.\")\n",
    "    print(\"Press SPACE to pause/resume. Press ESC to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        image = cv.flip(image, 1)\n",
    "        debug_image = copy.deepcopy(image)\n",
    "        \n",
    "        # Process hand detection\n",
    "        image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image_rgb.flags.writeable = False\n",
    "        results = hands.process(image_rgb)\n",
    "        image_rgb.flags.writeable = True\n",
    "        \n",
    "        # Handle key press\n",
    "        key = cv.waitKey(10)\n",
    "        \n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "        \n",
    "        # Toggle pause with SPACE\n",
    "        if key == 32:  # SPACE\n",
    "            is_paused = not is_paused\n",
    "            print(f\"Collection {'paused' if is_paused else 'resumed'}\")\n",
    "        \n",
    "        # Check for letter keys - sets current letter\n",
    "        if 97 <= key <= 122:  # lowercase a-z\n",
    "            letter = chr(key).upper()\n",
    "            if letter in STATIC_LETTERS:\n",
    "                current_letter = letter\n",
    "                is_paused = False  # Auto-resume when new letter selected\n",
    "                print(f\"Now collecting: {letter}\")\n",
    "        \n",
    "        # Collect sample if hand detected, letter selected, and not paused\n",
    "        if results.multi_hand_landmarks and current_letter and not is_paused:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "                \n",
    "                # Draw skeleton\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "                \n",
    "                processed_landmarks = pre_process_landmark(landmark_list)\n",
    "                \n",
    "                # Save to CSV with correct label index\n",
    "                label_index = ord(current_letter) - ord('A')  # A=0, B=1, etc.\n",
    "                with open(output_csv, 'a', newline='', encoding='utf-8') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([label_index] + processed_landmarks)\n",
    "                \n",
    "                collection_counts[current_letter] += 1\n",
    "        \n",
    "        # Check completion\n",
    "        all_complete = all(collection_counts[letter] >= TARGET_SAMPLES for letter in STATIC_LETTERS)\n",
    "        if all_complete:\n",
    "            print(\"\\nAll letters complete!\")\n",
    "            cap.release()\n",
    "            cv.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "        # Draw UI\n",
    "        debug_image = draw_collection_info(\n",
    "            debug_image,\n",
    "            current_letter,\n",
    "            collection_counts.get(current_letter, 0) if current_letter else 0,\n",
    "            TARGET_SAMPLES,\n",
    "            is_paused\n",
    "        )\n",
    "        \n",
    "        # Draw remaining letters list\n",
    "        debug_image = draw_remaining_letters(debug_image, collection_counts, TARGET_SAMPLES)\n",
    "        \n",
    "        cv.imshow('Hand Gesture Collection', debug_image)\n",
    "    \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "    print(\"\\nCollection Summary:\")\n",
    "    for letter in STATIC_LETTERS:\n",
    "        count = collection_counts[letter]\n",
    "        print(f\"{letter}: {count}/{TARGET_SAMPLES}\")\n",
    "    \n",
    "    return collection_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc8e0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Letters that need data collection\n",
    "STATIC_LETTERS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "TARGET_SAMPLES = 1246\n",
    "OUTPUT_CSV = Path('../data/dataset/_NEW_ngt_static_keypoint.csv')\n",
    "\n",
    "OUTPUT_CSV.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3cff4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection started. Press letter keys (A-Z) to collect.\n",
      "Press SPACE to pause/resume. Press ESC to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1769007239.187113       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection paused\n",
      "Now collecting: A\n",
      "Collection paused\n",
      "Now collecting: Q\n",
      "\n",
      "Collection Summary:\n",
      "A: 354/1246\n",
      "B: 0/1246\n",
      "C: 0/1246\n",
      "D: 0/1246\n",
      "E: 0/1246\n",
      "F: 0/1246\n",
      "G: 0/1246\n",
      "I: 0/1246\n",
      "K: 0/1246\n",
      "L: 0/1246\n",
      "M: 0/1246\n",
      "N: 0/1246\n",
      "O: 0/1246\n",
      "P: 0/1246\n",
      "Q: 0/1246\n",
      "R: 0/1246\n",
      "S: 0/1246\n",
      "T: 0/1246\n",
      "V: 0/1246\n",
      "W: 0/1246\n",
      "Y: 0/1246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': 354,\n",
       " 'B': 0,\n",
       " 'C': 0,\n",
       " 'D': 0,\n",
       " 'E': 0,\n",
       " 'F': 0,\n",
       " 'G': 0,\n",
       " 'I': 0,\n",
       " 'K': 0,\n",
       " 'L': 0,\n",
       " 'M': 0,\n",
       " 'N': 0,\n",
       " 'O': 0,\n",
       " 'P': 0,\n",
       " 'Q': 0,\n",
       " 'R': 0,\n",
       " 'S': 0,\n",
       " 'T': 0,\n",
       " 'V': 0,\n",
       " 'W': 0,\n",
       " 'Y': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_collection(output_csv=OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22c98fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch dataset has: ['A', 'D', 'E', 'G', 'H', 'J', 'K', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'W']\n",
      "Dutch indices: [0, 3, 4, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 22]\n",
      "\n",
      "ASL keeping: ['B', 'C', 'F', 'I', 'L', 'U', 'V', 'X', 'Y', 'Z']\n",
      "ASL samples: 12467\n",
      "Dutch samples: 35047\n",
      "\n",
      "Total combined: 47514 samples\n"
     ]
    }
   ],
   "source": [
    "# Load full alphabet\n",
    "with open('../data/dataset/keypoint_classifier_label.csv', 'r', encoding='utf-8-sig') as f:\n",
    "    ALL_LETTERS = [row[0] for row in csv.reader(f)]\n",
    "\n",
    "# Step 1: Find which letters are in Dutch dataset\n",
    "dutch_indices = set()\n",
    "with open('../data/dataset/new_samples.csv', 'r', encoding='utf-8-sig') as f:\n",
    "    for row in csv.reader(f):\n",
    "        if row:\n",
    "            dutch_indices.add(int(row[0]))\n",
    "\n",
    "dutch_letters = [ALL_LETTERS[i] for i in sorted(dutch_indices)]\n",
    "print(f\"Dutch dataset has: {dutch_letters}\")\n",
    "print(f\"Dutch indices: {sorted(dutch_indices)}\")\n",
    "\n",
    "# Step 2: Get ASL data for letters NOT in Dutch\n",
    "asl_data = []\n",
    "with open('../data/dataset/asl_keypoint.csv', 'r', encoding='utf-8-sig') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if row:\n",
    "            label_idx = int(row[0])\n",
    "            if label_idx not in dutch_indices:  # Keep if NOT in Dutch\n",
    "                asl_data.append(row)\n",
    "\n",
    "asl_kept_letters = sorted(set(ALL_LETTERS[int(row[0])] for row in asl_data))\n",
    "print(f\"\\nASL keeping: {asl_kept_letters}\")\n",
    "print(f\"ASL samples: {len(asl_data)}\")\n",
    "\n",
    "# Step 3: Get all Dutch data\n",
    "dutch_data = []\n",
    "with open('../data/dataset/new_samples.csv', 'r', encoding='utf-8-sig') as f:\n",
    "    dutch_data = list(csv.reader(f))\n",
    "\n",
    "print(f\"Dutch samples: {len(dutch_data)}\")\n",
    "\n",
    "# Step 4: Combine\n",
    "combined = asl_data + dutch_data\n",
    "\n",
    "with open('../data/dataset/ngt_keypoint.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(combined)\n",
    "\n",
    "print(f\"\\nTotal combined: {len(combined)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffae7354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter counts in ngt_keypoint.csv:\n",
      "----------------------------------------\n",
      " 0 (A):  1898\n",
      " 1 (B):  1281\n",
      " 2 (C):   578\n",
      " 3 (D):  2275\n",
      " 4 (E):  2340\n",
      " 5 (F):  1024\n",
      " 6 (G):  2281\n",
      " 7 (H):  3209\n",
      " 8 (I):  1021\n",
      " 9 (J):  2746\n",
      "10 (K):  1870\n",
      "11 (L):  1417\n",
      "12 (M):  1912\n",
      "13 (N):  1962\n",
      "14 (O):  1918\n",
      "15 (P):  1902\n",
      "16 (Q):  1891\n",
      "17 (R):  3018\n",
      "18 (S):  1965\n",
      "19 (T):  1895\n",
      "20 (U):  1182\n",
      "21 (V):  1227\n",
      "22 (W):  1965\n",
      "23 (X):  1094\n",
      "24 (Y):  2179\n",
      "25 (Z):  1464\n",
      "----------------------------------------\n",
      "Total samples: 47514\n",
      "Unique letters: 26\n"
     ]
    }
   ],
   "source": [
    "# Check the combined dataset\n",
    "combined_labels = []\n",
    "with open('../data/dataset/ngt_keypoint.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if row:\n",
    "            combined_labels.append(int(row[0]))\n",
    "\n",
    "# Load alphabet\n",
    "with open('../data/dataset/keypoint_classifier_label.csv', 'r', encoding='utf-8-sig') as f:\n",
    "    ALL_LETTERS = [row[0] for row in csv.reader(f)]\n",
    "\n",
    "print(\"Letter counts in ngt_keypoint.csv:\")\n",
    "print(\"-\" * 40)\n",
    "for label_idx in sorted(set(combined_labels)):\n",
    "    letter = ALL_LETTERS[label_idx]\n",
    "    count = combined_labels.count(label_idx)\n",
    "    print(f\"{label_idx:2d} ({letter}): {count:5d}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total samples: {len(combined_labels)}\")\n",
    "print(f\"Unique letters: {len(set(combined_labels))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerspell-venv-af5b43d44a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
