{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89c6f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a576ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngt_static_classifier = Path('./data/models/ngt_static_classifier_normalized.pkl')\n",
    "ngt_dynamic_landmarks = Path('./data/dataset/ngt_dynamic_landmarks.csv')\n",
    "ngt_dynamic_landmarks_clean = Path('./data/dataset/ngt_dynamic_landmarks_clean.csv')\n",
    "ngt_dynamic_classifier = Path('./data/models/ngt_dynamic_classifier.pkl')\n",
    "ngt_dynamic_scaler = Path('./data/models/ngt_dynamic_scaler.pkl')\n",
    "ngt_static_scaler = Path('./data/models/ngt_static_scaler.pkl')\n",
    "ngt_dynamic_classifier.parent.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23803a7b",
   "metadata": {},
   "source": [
    "Cleanup the dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1961a3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header has 66 columns\n",
      "\n",
      "Found 1 bad lines out of 5400 total\n",
      "\n",
      "First few bad lines:\n",
      "Line 901: 131 columns - H,29,29,0.6098656058311462,0.8449515700340271,4.309395364998636e-07,0.5704282522201538,0.79714471101...\n",
      "\n",
      "Cleaned file saved: data/dataset/ngt_dynamic_landmarks_clean.csv\n",
      "Removed 1 corrupted rows\n",
      "Kept 5398 good rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read line by line to find bad rows\n",
    "bad_lines = []\n",
    "good_lines = []\n",
    "\n",
    "with open(ngt_dynamic_landmarks, 'r') as f:\n",
    "    header = f.readline()\n",
    "    expected_cols = len(header.strip().split(','))\n",
    "    print(f\"Header has {expected_cols} columns\")\n",
    "    \n",
    "    good_lines.append(header)\n",
    "    \n",
    "    for i, line in enumerate(f, start=2):\n",
    "        cols = len(line.strip().split(','))\n",
    "        if cols != expected_cols:\n",
    "            bad_lines.append((i, cols, line[:100]))  # Store line number, column count, preview\n",
    "        else:\n",
    "            good_lines.append(line)\n",
    "\n",
    "print(f\"\\nFound {len(bad_lines)} bad lines out of {i} total\")\n",
    "\n",
    "if bad_lines:\n",
    "    print(\"\\nFirst few bad lines:\")\n",
    "    for line_num, cols, preview in bad_lines[:5]:\n",
    "        print(f\"Line {line_num}: {cols} columns - {preview}...\")\n",
    "\n",
    "# Write cleaned file\n",
    "with open(ngt_dynamic_landmarks_clean, 'w') as f:\n",
    "    f.writelines(good_lines)\n",
    "\n",
    "print(f\"\\nCleaned file saved: {ngt_dynamic_landmarks_clean}\")\n",
    "print(f\"Removed {len(bad_lines)} corrupted rows\")\n",
    "print(f\"Kept {len(good_lines)-1} good rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab21276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_features(coords_array):\n",
    "    \"\"\"Extract features for dynamic prediction\"\"\"\n",
    "    coords = coords_array.reshape(len(coords_array), 21, 3)\n",
    "    features = []\n",
    "    features.extend(coords.mean(axis=0).flatten())\n",
    "    if len(coords) > 1:\n",
    "        features.extend(coords.std(axis=0).flatten())\n",
    "    else:\n",
    "        features.extend(np.zeros(63))\n",
    "    if len(coords) > 1:\n",
    "        features.extend((coords[-1] - coords[0]).flatten())\n",
    "    else:\n",
    "        features.extend(np.zeros(63))\n",
    "    for lm_idx in range(21):\n",
    "        if len(coords) > 1:\n",
    "            path = coords[:, lm_idx, :]\n",
    "            dists = np.linalg.norm(np.diff(path, axis=0), axis=1)\n",
    "            features.append(dists.sum())\n",
    "        else:\n",
    "            features.append(0.0)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60d39779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features from 180 sequences\n",
      "Feature vector size: 210\n",
      "\n",
      "Dynamic-only accuracy: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       1.00      1.00      1.00         6\n",
      "           J       1.00      1.00      1.00         6\n",
      "           U       1.00      1.00      1.00         6\n",
      "           X       1.00      1.00      1.00         6\n",
      "           Z       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "Saved to data/models/ngt_dynamic_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "dynamic_df = pd.read_csv(ngt_dynamic_landmarks_clean)\n",
    "\n",
    "# Extract features from sequences\n",
    "dynamic_features = []\n",
    "dynamic_labels = []\n",
    "\n",
    "coord_cols = [col for col in dynamic_df.columns if col not in ['letter', 'sample_id', 'frame']]\n",
    "\n",
    "for (letter, sample_id), group in dynamic_df.groupby(['letter', 'sample_id']):\n",
    "    coords = group[coord_cols].values\n",
    "    features = extract_sequence_features(coords)\n",
    "    dynamic_features.append(features)\n",
    "    dynamic_labels.append(letter)\n",
    "\n",
    "print(f\"Extracted features from {len(dynamic_features)} sequences\")\n",
    "print(f\"Feature vector size: {len(dynamic_features[0])}\")\n",
    "\n",
    "# Convert to dataframe\n",
    "X = pd.DataFrame(dynamic_features)\n",
    "y = pd.Series(dynamic_labels)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_normalized, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"\\nDynamic-only accuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save\n",
    "joblib.dump(clf, ngt_dynamic_classifier)\n",
    "joblib.dump(scaler, ngt_dynamic_scaler)\n",
    "print(f\"\\nSaved to {ngt_dynamic_classifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67c5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "import numpy as np\n",
    "from collections import deque, Counter\n",
    "\n",
    "# Load STATIC model \n",
    "static_clf = joblib.load(ngt_static_classifier)\n",
    "static_scaler = None  # We'll load this if it exists\n",
    "\n",
    "try:\n",
    "    dynamic_clf = joblib.load(ngt_dynamic_classifier)\n",
    "    dynamic_scaler = joblib.load(ngt_dynamic_scaler)\n",
    "except:\n",
    "    print(\"Dynamic model not found - train it first!\")\n",
    "    dynamic_clf = None\n",
    "    dynamic_scaler = None\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "DYNAMIC_LETTERS = ['H', 'J', 'U', 'X', 'Z']\n",
    "BUFFER_SIZE = 30\n",
    "CONFIDENCE_THRESHOLD = 0.45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfeb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGT Recognition - Hybrid Static/Dynamic\n",
      "Press 'q' to quit\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768853667.922383  707493 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1768853667.946604  712311 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1768853667.955082  712311 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1768853668.245109  712308 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "def normalize_static_landmarks(landmarks):\n",
    "    \"\"\"Normalize for static prediction\"\"\"\n",
    "    coords = np.array([[lm.x, lm.y, lm.z] for lm in landmarks])\n",
    "    wrist = coords[0]\n",
    "    coords = coords - wrist\n",
    "    hand_size = np.linalg.norm(coords[12] - coords[0])\n",
    "    if hand_size > 0:\n",
    "        coords = coords / hand_size\n",
    "    return coords.flatten()\n",
    "\n",
    "def extract_sequence_features(coords_array):\n",
    "    \"\"\"Extract features for dynamic prediction\"\"\"\n",
    "    coords = coords_array.reshape(len(coords_array), 21, 3)\n",
    "    features = []\n",
    "    features.extend(coords.mean(axis=0).flatten())\n",
    "    if len(coords) > 1:\n",
    "        features.extend(coords.std(axis=0).flatten())\n",
    "    else:\n",
    "        features.extend(np.zeros(63))\n",
    "    if len(coords) > 1:\n",
    "        features.extend((coords[-1] - coords[0]).flatten())\n",
    "    else:\n",
    "        features.extend(np.zeros(63))\n",
    "    for lm_idx in range(21):\n",
    "        if len(coords) > 1:\n",
    "            path = coords[:, lm_idx, :]\n",
    "            dists = np.linalg.norm(np.diff(path, axis=0), axis=1)\n",
    "            features.append(dists.sum())\n",
    "        else:\n",
    "            features.append(0.0)\n",
    "    return np.array(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2158602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "frame_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "static_predictions = deque(maxlen=BUFFER_SIZE)\n",
    "final_predictions = deque(maxlen=5)\n",
    "\n",
    "print(\"NGT Recognition - Hybrid Static/Dynamic\")\n",
    "print(\"Press 'q' to quit\\n\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.7\n",
    ") as hands:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS\n",
    "                )\n",
    "                \n",
    "                # Step 1: Always predict with static model\n",
    "                normalized_coords = normalize_static_landmarks(hand_landmarks.landmark)\n",
    "                static_pred = static_clf.predict([normalized_coords])[0]\n",
    "                static_proba = static_clf.predict_proba([normalized_coords])[0]\n",
    "                static_conf = static_proba.max()\n",
    "                \n",
    "                # Buffer the frame and prediction\n",
    "                coords = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()\n",
    "                frame_buffer.append(coords)\n",
    "                static_predictions.append(static_pred)\n",
    "                \n",
    "                # Step 3: Check if static predictions are changing\n",
    "                if len(static_predictions) >= 10:\n",
    "                    recent_static = list(static_predictions)[-10:]\n",
    "                    unique_predictions = len(set(recent_static))\n",
    "                    \n",
    "                    # If predictions are unstable AND we have full buffer, try dynamic\n",
    "                    if unique_predictions > 3 and len(frame_buffer) == BUFFER_SIZE and dynamic_clf:\n",
    "                        buffer_array = np.array(frame_buffer)\n",
    "                        dyn_features = extract_sequence_features(buffer_array)\n",
    "                        dyn_features_norm = dynamic_scaler.transform(dyn_features.reshape(1, -1))\n",
    "                        \n",
    "                        dyn_pred = dynamic_clf.predict(dyn_features_norm)[0]\n",
    "                        dyn_proba = dynamic_clf.predict_proba(dyn_features_norm)[0]\n",
    "                        dyn_conf = dyn_proba.max()\n",
    "                        \n",
    "                        # Use dynamic prediction if confident\n",
    "                        if dyn_conf >= CONFIDENCE_THRESHOLD:\n",
    "                            final_predictions.append((dyn_pred, dyn_conf))\n",
    "                            frame_buffer.clear()\n",
    "                            static_predictions.clear()\n",
    "                    \n",
    "                    # Use static prediction if stable and confident\n",
    "                    elif unique_predictions <= 2 and static_conf >= CONFIDENCE_THRESHOLD:\n",
    "                        most_common = Counter(recent_static).most_common(1)[0][0]\n",
    "                        final_predictions.append((most_common, static_conf))\n",
    "        else:\n",
    "            frame_buffer.clear()\n",
    "            static_predictions.clear()\n",
    "        \n",
    "        # Step 4: Display last 5 confident predictions\n",
    "        if final_predictions:\n",
    "            # Get most recent prediction\n",
    "            last_pred, last_conf = final_predictions[-1]\n",
    "            \n",
    "            letter_type = \"DYNAMIC\" if last_pred in DYNAMIC_LETTERS else \"STATIC\"\n",
    "            cv2.putText(frame, f\"{last_pred}\", \n",
    "                       (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 5)\n",
    "            cv2.putText(frame, f\"{letter_type} - {last_conf:.0%}\", \n",
    "                       (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show history\n",
    "            history_text = \"History: \" + \" \".join([p[0] for p in final_predictions])\n",
    "            cv2.putText(frame, history_text, \n",
    "                       (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Debug info\n",
    "        cv2.putText(frame, f\"Buffer: {len(frame_buffer)}\", \n",
    "                   (10, frame.shape[0] - 20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('NGT Recognition', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fefd74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading ./static_dynamic.ipynb in format ipynb\n",
      "[jupytext] Writing ./static_dynamic.py\n"
     ]
    }
   ],
   "source": [
    "! jupytext --to py './static_dynamic.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e105a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerspell-venv-af5b43d44a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
