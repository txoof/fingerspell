{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517e930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import itertools\n",
    "from collections import deque\n",
    "\n",
    "# Paths\n",
    "model_path = Path('../data/model/keypoint_classifier.tflite')\n",
    "# Labels\n",
    "LABELS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', \n",
    "          'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b4e39",
   "metadata": {},
   "source": [
    "## Functions & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a54e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS calculator loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CvFpsCalc:\n",
    "    def __init__(self, buffer_len=10):\n",
    "        self._start_tick = cv.getTickCount()\n",
    "        self._freq = 1000.0 / cv.getTickFrequency()\n",
    "        self._difftimes = deque(maxlen=buffer_len)\n",
    "\n",
    "    def get(self):\n",
    "        current_tick = cv.getTickCount()\n",
    "        different_time = (current_tick - self._start_tick) * self._freq\n",
    "        self._start_tick = current_tick\n",
    "        self._difftimes.append(different_time)\n",
    "        fps = 1000.0 / (sum(self._difftimes) / len(self._difftimes))\n",
    "        return round(fps, 2)\n",
    "\n",
    "print(\"FPS calculator loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd477b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "class KeyPointClassifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=str(model_path))\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "    \n",
    "    def __call__(self, landmark_list):\n",
    "        self.interpreter.set_tensor(\n",
    "            self.input_details[0][\"index\"], \n",
    "            np.array([landmark_list], dtype=np.float32)\n",
    "        )\n",
    "        self.interpreter.invoke()\n",
    "        result = self.interpreter.get_tensor(self.output_details[0][\"index\"])\n",
    "        return np.argmax(np.squeeze(result))\n",
    "\n",
    "# Load classifier\n",
    "classifier = KeyPointClassifier(model_path)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b120cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_landmark_list(image, landmarks):\n",
    "    \"\"\"Extract landmark coordinates.\"\"\"\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "    landmark_point = []\n",
    "    for landmark in landmarks.landmark:\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "    return landmark_point\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    \"\"\"Normalize landmarks to relative coordinates.\"\"\"\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "    \n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = temp_landmark_list[0][0], temp_landmark_list[0][1]\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        temp_landmark_list[index][0] -= base_x\n",
    "        temp_landmark_list[index][1] -= base_y\n",
    "    \n",
    "    # Flatten\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "    \n",
    "    # Normalize\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "    temp_landmark_list = list(map(lambda n: n / max_value, temp_landmark_list))\n",
    "    \n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ec4900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton drawing function loaded\n"
     ]
    }
   ],
   "source": [
    "def draw_landmarks(image, landmark_point):\n",
    "    \"\"\"Draw hand skeleton.\"\"\"\n",
    "    if len(landmark_point) > 0:\n",
    "        # Thumb\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[3]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[3]), tuple(landmark_point[4]), (255, 255, 255), 2)\n",
    "\n",
    "        # Index finger\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[6]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[6]), tuple(landmark_point[7]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[7]), tuple(landmark_point[8]), (255, 255, 255), 2)\n",
    "\n",
    "        # Middle finger\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[10]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[10]), tuple(landmark_point[11]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[11]), tuple(landmark_point[12]), (255, 255, 255), 2)\n",
    "\n",
    "        # Ring finger\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[14]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[14]), tuple(landmark_point[15]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[15]), tuple(landmark_point[16]), (255, 255, 255), 2)\n",
    "\n",
    "        # Pinky\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[18]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[18]), tuple(landmark_point[19]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[19]), tuple(landmark_point[20]), (255, 255, 255), 2)\n",
    "\n",
    "        # Palm\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[0]), tuple(landmark_point[1]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[1]), tuple(landmark_point[2]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[2]), tuple(landmark_point[5]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[5]), tuple(landmark_point[9]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[9]), tuple(landmark_point[13]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[13]), tuple(landmark_point[17]), (255, 255, 255), 2)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]), (0, 0, 0), 6)\n",
    "        cv.line(image, tuple(landmark_point[17]), tuple(landmark_point[0]), (255, 255, 255), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "print(\"Skeleton drawing function loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46782a7b",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee74aa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768920548.223457       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c007716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting detection. Press ESC to quit, Ctrl+D for debug mode.\n",
      "Debug mode: ON\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "fps_calc = CvFpsCalc(buffer_len=10)\n",
    "\n",
    "debug_mode = False\n",
    "\n",
    "print(\"Starting detection. Press ESC to quit, Ctrl+D for debug mode.\")\n",
    "\n",
    "while True:\n",
    "    fps = fps_calc.get()\n",
    "    \n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    image = cv.flip(image, 1)\n",
    "    debug_image = copy.deepcopy(image)\n",
    "    \n",
    "    image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "    detected_letter = \"\"\n",
    "    confidence = 0.0\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "            \n",
    "            # Draw skeleton only in debug mode\n",
    "            if debug_mode:\n",
    "                debug_image = draw_landmarks(debug_image, landmark_list)\n",
    "            \n",
    "            processed = pre_process_landmark(landmark_list)\n",
    "            hand_sign_id = classifier(processed)\n",
    "            detected_letter = LABELS[hand_sign_id]\n",
    "            \n",
    "            # Get confidence score\n",
    "            classifier.interpreter.invoke()\n",
    "            result = classifier.interpreter.get_tensor(classifier.output_details[0][\"index\"])\n",
    "            confidence = np.max(result)\n",
    "    \n",
    "    # Display detected letter\n",
    "    cv.putText(debug_image, detected_letter, (10, 60),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), 3)\n",
    "    \n",
    "    # Display confidence in debug mode\n",
    "    if debug_mode and detected_letter:\n",
    "        cv.putText(debug_image, f\"Confidence: {confidence:.2%}\", (10, 110),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "    \n",
    "    # Display FPS only in debug mode\n",
    "    if debug_mode:\n",
    "        cv.putText(debug_image, f\"FPS: {fps}\", (10, debug_image.shape[0] - 20),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv.putText(debug_image, \"DEBUG MODE\", (debug_image.shape[1] - 200, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    cv.imshow('NGT Fingerspelling', debug_image)\n",
    "    \n",
    "    # Handle keypresses\n",
    "    key = cv.waitKey(10)\n",
    "    if key == 27:  # ESC\n",
    "        break\n",
    "    elif key == 4:  # Ctrl+D\n",
    "        debug_mode = not debug_mode\n",
    "        print(f\"Debug mode: {'ON' if debug_mode else 'OFF'}\")\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3e2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerspell-venv-af5b43d44a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
