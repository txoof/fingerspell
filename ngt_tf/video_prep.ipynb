{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130b2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d825a549",
   "metadata": {},
   "source": [
    "## Convert webm video to mp4\n",
    "\n",
    "Convert the video from Vera de Kok from webm to mp4 for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72dcb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_webm_to_mp4(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Convert WebM video to MP4 format for better OpenCV compatibility.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input .webm file\n",
    "        output_path: Path for output .mp4 file (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Path to converted file\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = input_path.replace('.webm', '.mp4')\n",
    "    \n",
    "    command = [\n",
    "        'ffmpeg',\n",
    "        '-i', input_path,\n",
    "        '-c:v', 'libx264',  # H264 codec\n",
    "        '-preset', 'medium',  # Balance speed/quality\n",
    "        '-crf', '23',  # Quality (lower = better, 18-28 typical)\n",
    "        '-c:a', 'aac',  # Audio codec\n",
    "        '-b:a', '128k',  # Audio bitrate\n",
    "        '-y',  # Overwrite output file\n",
    "        output_path\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Conversion successful: {output_path}\")\n",
    "        return output_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Conversion failed: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to do this once!\n",
    "# convert_webm_to_mp4('../assets/NGT_handalfabet.webm', '../assets/NGT_handalfabet.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e36da5",
   "metadata": {},
   "source": [
    "## Make timestamp markers\n",
    "\n",
    "Divide the video by timestamp markers to make playback easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e83f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "def create_timestamp_markers(video_path, output_json='letter_timestamps.json'):\n",
    "    \"\"\"\n",
    "    Interactive tool to mark timestamp boundaries for each letter A-Z.\n",
    "    Uses live preview with looping playback.\n",
    "    \n",
    "    Controls:\n",
    "    - SPACE: Replay current segment\n",
    "    - H/L: Adjust start time -/+ 0.05s (vim left/right)\n",
    "    - J/K: Adjust end time -/+ 0.05s (vim down/up)  \n",
    "    - Shift+H/L: Adjust start time -/+ 0.5s (coarse)\n",
    "    - Shift+J/K: Adjust end time -/+ 0.5s (coarse)\n",
    "    - Ctrl+N: Accept and move to next letter\n",
    "    - Ctrl+P: Go back to previous letter\n",
    "    - Q: Quit and save\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    letters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "    timestamps = {}  # Will store {letter: {\"start\": x, \"end\": y}}\n",
    "    \n",
    "    current_letter_idx = 0\n",
    "    \n",
    "    # Initialize first letter with reasonable defaults\n",
    "    current_start = 0.0\n",
    "    current_end = min(2.0, duration)\n",
    "    \n",
    "    print(f\"Video: {duration:.1f}s, {fps:.1f} FPS\")\n",
    "    print(\"\\nControls:\")\n",
    "    print(\"  SPACE: Replay segment\")\n",
    "    print(\"  H/L: Start time -/+ 0.05s\")\n",
    "    print(\"  J/K: End time -/+ 0.05s\")\n",
    "    print(\"  Shift+H/L: Start time -/+ 0.5s\")\n",
    "    print(\"  Shift+J/K: End time -/+ 0.5s\")\n",
    "    print(\"  Ctrl+N: Next letter\")\n",
    "    print(\"  Ctrl+P: Previous letter\")\n",
    "    print(\"  Q: Quit and save\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    \n",
    "    cv2.namedWindow('Mark Timestamps')\n",
    "    \n",
    "    while current_letter_idx < len(letters):\n",
    "        letter = letters[current_letter_idx]\n",
    "        \n",
    "        # If returning to a previously marked letter, load its values\n",
    "        if letter in timestamps:\n",
    "            current_start = timestamps[letter][\"start\"]\n",
    "            current_end = timestamps[letter][\"end\"]\n",
    "        \n",
    "        print(f\"\\nMarking letter: {letter} ({current_letter_idx + 1}/26)\")\n",
    "        print(f\"  Start: {current_start:.2f}s | End: {current_end:.2f}s\")\n",
    "        \n",
    "        adjusting = True\n",
    "        \n",
    "        while adjusting:\n",
    "            # Play segment in loop\n",
    "            start_frame = int(current_start * fps)\n",
    "            end_frame = int(current_end * fps)\n",
    "            \n",
    "            # Ensure valid range\n",
    "            start_frame = max(0, min(start_frame, total_frames - 1))\n",
    "            end_frame = max(start_frame + 1, min(end_frame, total_frames))\n",
    "            \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "            current_frame = start_frame\n",
    "            \n",
    "            loop_count = 0\n",
    "            \n",
    "            while current_frame < end_frame and adjusting:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    current_frame = start_frame\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "                    continue\n",
    "                \n",
    "                # Display info\n",
    "                display_frame = frame.copy()\n",
    "                current_time = current_frame / fps\n",
    "                \n",
    "                cv2.putText(display_frame, f\"Letter: {letter} ({current_letter_idx + 1}/26)\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(display_frame, f\"Start: {current_start:.2f}s | End: {current_end:.2f}s | Dur: {current_end - current_start:.2f}s\", \n",
    "                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                cv2.putText(display_frame, f\"Current: {current_time:.2f}s\", \n",
    "                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n",
    "                \n",
    "                # Show marked letters\n",
    "                marked_count = len(timestamps)\n",
    "                cv2.putText(display_frame, f\"Marked: {marked_count}/26\", \n",
    "                           (10, display_frame.shape[0] - 10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "                \n",
    "                cv2.imshow('Mark Timestamps', display_frame)\n",
    "                \n",
    "                # Check for key press\n",
    "                key = cv2.waitKey(int(1000/fps)) & 0xFF\n",
    "                \n",
    "                if key == ord(' '):\n",
    "                    # Replay - restart loop\n",
    "                    current_frame = start_frame - 1\n",
    "                \n",
    "                elif key == ord('h'):\n",
    "                    # Decrease start time\n",
    "                    current_start = max(0, round(current_start - 0.05, 2))\n",
    "                    print(f\"  Start: {current_start:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('l'):\n",
    "                    # Increase start time\n",
    "                    current_start = min(current_end - 0.1, round(current_start + 0.05, 2))\n",
    "                    print(f\"  Start: {current_start:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('j'):\n",
    "                    # Decrease end time\n",
    "                    current_end = max(current_start + 0.1, round(current_end - 0.05, 2))\n",
    "                    print(f\"  End: {current_end:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('k'):\n",
    "                    # Increase end time\n",
    "                    current_end = min(duration, round(current_end + 0.05, 2))\n",
    "                    print(f\"  End: {current_end:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('H'):\n",
    "                    # Decrease start time (coarse)\n",
    "                    current_start = max(0, round(current_start - 0.5, 2))\n",
    "                    print(f\"  Start: {current_start:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('L'):\n",
    "                    # Increase start time (coarse)\n",
    "                    current_start = min(current_end - 0.1, round(current_start + 0.5, 2))\n",
    "                    print(f\"  Start: {current_start:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('J'):\n",
    "                    # Decrease end time (coarse)\n",
    "                    current_end = max(current_start + 0.1, round(current_end - 0.5, 2))\n",
    "                    print(f\"  End: {current_end:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == ord('K'):\n",
    "                    # Increase end time (coarse)\n",
    "                    current_end = min(duration, round(current_end + 0.5, 2))\n",
    "                    print(f\"  End: {current_end:.2f}s\")\n",
    "                    break\n",
    "                \n",
    "                elif key == 14:  # Ctrl+N\n",
    "                    # Save and move to next\n",
    "                    timestamps[letter] = {\"start\": current_start, \"end\": current_end}\n",
    "                    print(f\"  Saved {letter}: {current_start:.2f}s - {current_end:.2f}s\")\n",
    "                    current_letter_idx += 1\n",
    "                    # Set next letter to start where this one ended\n",
    "                    current_start = current_end\n",
    "                    current_end = min(current_start + 2.0, duration)\n",
    "                    adjusting = False\n",
    "                    break\n",
    "                \n",
    "                elif key == 16:  # Ctrl+P\n",
    "                    # Go to previous letter\n",
    "                    if current_letter_idx > 0:\n",
    "                        current_letter_idx -= 1\n",
    "                        adjusting = False\n",
    "                        break\n",
    "                \n",
    "                elif key == ord('q'):\n",
    "                    # Quit and save\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    \n",
    "                    # Save what we have\n",
    "                    with open(output_json, 'w') as f:\n",
    "                        json.dump(timestamps, f, indent=2)\n",
    "                    \n",
    "                    print(f\"\\nSaved {len(timestamps)} timestamps to {output_json}\")\n",
    "                    return timestamps\n",
    "                \n",
    "                current_frame += 1\n",
    "                \n",
    "                # Loop back to start\n",
    "                if current_frame >= end_frame:\n",
    "                    current_frame = start_frame\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "                    loop_count += 1\n",
    "    \n",
    "    # Finished all letters\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    with open(output_json, 'w') as f:\n",
    "        json.dump(timestamps, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nSaved all 26 timestamps to {output_json}\")\n",
    "    return timestamps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7043d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this once or to adjust markers\n",
    "# timestamps = create_timestamp_markers('../assets/letter_timestamps.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83c315",
   "metadata": {},
   "source": [
    "## Proof of Concet Video Players\n",
    "\n",
    "### Simple Hint Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ace382be",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_path = '../assets/letter_timestamps.json'\n",
    "video_path = '../assets/NGT_handalfabet.mp4'\n",
    "landmarks_pkl = '../assets/video_landmarks.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad0e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "\n",
    "class VideoHintPlayer:\n",
    "    \"\"\"\n",
    "    Plays video segments as hints for finger spelling letters.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_path, timestamps_path='letter_timestamps.json'):\n",
    "        self.video_path = video_path\n",
    "        \n",
    "        # Load timestamps\n",
    "        with open(timestamps_path, 'r') as f:\n",
    "            self.timestamps = json.load(f)\n",
    "        \n",
    "        print(f\"Loaded {len(self.timestamps)} letter hints\")\n",
    "    \n",
    "    def play_hint(self, letter, window_name='Hint'):\n",
    "        \"\"\"\n",
    "        Play video segment for specified letter.\n",
    "        \n",
    "        Args:\n",
    "            letter: Letter to show (A-Z)\n",
    "            window_name: OpenCV window name\n",
    "        \n",
    "        Returns:\n",
    "            True if played successfully, False otherwise\n",
    "        \"\"\"\n",
    "        letter = letter.upper()\n",
    "        \n",
    "        if letter not in self.timestamps:\n",
    "            print(f\"No timestamp for letter: {letter}\")\n",
    "            return False\n",
    "        \n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Get start and end times\n",
    "        start_time = self.timestamps[letter][\"start\"]\n",
    "        end_time = self.timestamps[letter][\"end\"]\n",
    "        \n",
    "        start_frame = int(start_time * fps)\n",
    "        end_frame = int(end_time * fps)\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        \n",
    "        current_frame = start_frame\n",
    "        \n",
    "        while current_frame < end_frame:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Add letter label\n",
    "            cv2.putText(frame, f\"Letter: {letter}\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(window_name, frame)\n",
    "            \n",
    "            # Wait appropriate time for playback speed\n",
    "            # Allow 'q' to skip hint early\n",
    "            if cv2.waitKey(int(1000/fps)) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            current_frame += 1\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyWindow(window_name)\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd143106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 letter hints\n",
      "Playing hint for T...\n",
      "Playing hint for A...\n",
      "Playing hint for C...\n",
      "Playing hint for O...\n"
     ]
    }
   ],
   "source": [
    "# Test a few letters\n",
    "hint_player = VideoHintPlayer(video_path=video_path, timestamps_path=timestamps_path)\n",
    "for letter in ['T', 'A', 'C', 'O']:\n",
    "    print(f\"Playing hint for {letter}...\")\n",
    "    hint_player.play_hint(letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2088a3",
   "metadata": {},
   "source": [
    "### Video Player with Landmarks\n",
    "\n",
    "Add skeleton landmarks for playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37f19569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import mediapipe as mp\n",
    "\n",
    "class AnnotatedVideoHintPlayer:\n",
    "    \"\"\"\n",
    "    Plays video segments with hand landmark annotations to help users\n",
    "    understand finger positioning.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_path, timestamps_path='letter_timestamps.json'):\n",
    "        self.video_path = video_path\n",
    "        \n",
    "        # Load timestamps\n",
    "        with open(timestamps_path, 'r') as f:\n",
    "            self.timestamps = json.load(f)\n",
    "        \n",
    "        # Initialize MediaPipe\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=1,\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        print(f\"Loaded {len(self.timestamps)} letter hints\")\n",
    "    \n",
    "    def play_hint(self, letter, window_name='Hint - Watch Hand Position', show_landmarks=True):\n",
    "        \"\"\"\n",
    "        Play video segment with optional hand landmark overlay.\n",
    "        \n",
    "        Args:\n",
    "            letter: Letter to show (A-Z)\n",
    "            window_name: OpenCV window name\n",
    "            show_landmarks: Whether to overlay hand skeleton\n",
    "        \n",
    "        Returns:\n",
    "            True if played successfully, False otherwise\n",
    "        \"\"\"\n",
    "        letter = letter.upper()\n",
    "        \n",
    "        if letter not in self.timestamps:\n",
    "            print(f\"No timestamp for letter: {letter}\")\n",
    "            return False\n",
    "        \n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Get start and end times\n",
    "        start_time = self.timestamps[letter][\"start\"]\n",
    "        end_time = self.timestamps[letter][\"end\"]\n",
    "        \n",
    "        start_frame = int(start_time * fps)\n",
    "        end_frame = int(end_time * fps)\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        \n",
    "        current_frame = start_frame\n",
    "        \n",
    "        while current_frame < end_frame:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            # Add hand landmarks if requested\n",
    "            if show_landmarks:\n",
    "                # Convert to RGB for MediaPipe\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = self.hands.process(frame_rgb)\n",
    "                \n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        # Draw landmarks\n",
    "                        self.mp_drawing.draw_landmarks(\n",
    "                            display_frame,\n",
    "                            hand_landmarks,\n",
    "                            self.mp_hands.HAND_CONNECTIONS,\n",
    "                            self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                            self.mp_drawing_styles.get_default_hand_connections_style()\n",
    "                        )\n",
    "            \n",
    "            # Add helpful text\n",
    "            cv2.putText(display_frame, f\"Letter: {letter}\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(display_frame, \"Watch the hand position\", \n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow(window_name, display_frame)\n",
    "            \n",
    "            # Allow early exit\n",
    "            if cv2.waitKey(int(1000/fps)) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            current_frame += 1\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyWindow(window_name)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'hands'):\n",
    "            self.hands.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e9abcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768937450.188827       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 letter hints\n",
      "Playing hint for T...\n",
      "Playing hint for A...\n",
      "Playing hint for C...\n",
      "Playing hint for O...\n"
     ]
    }
   ],
   "source": [
    "# Test a few letters\n",
    "hint_player = AnnotatedVideoHintPlayer(video_path=video_path, timestamps_path=timestamps_path)\n",
    "for letter in ['T', 'A', 'C', 'O']:\n",
    "    print(f\"Playing hint for {letter}...\")\n",
    "    hint_player.play_hint(letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e3c14",
   "metadata": {},
   "source": [
    "### Extract Landmarks and Playback Skeleton\n",
    "\n",
    "Extract the landmarks from the videos and then playback just the skeleton, or use with a hand model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a16a0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "\n",
    "class VideoLandmarkExtractor:\n",
    "    \"\"\"\n",
    "    Extract hand landmarks from reference video segments.\n",
    "    Saves them for later use in animated hints.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_path, timestamps_path='letter_timestamps.json'):\n",
    "        self.video_path = video_path\n",
    "        \n",
    "        # Load timestamps\n",
    "        with open(timestamps_path, 'r') as f:\n",
    "            self.timestamps = json.load(f)\n",
    "        \n",
    "        # Initialize MediaPipe\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        print(f\"Loaded {len(self.timestamps)} letter segments\")\n",
    "    \n",
    "    def extract_landmarks_for_letter(self, letter):\n",
    "        \"\"\"\n",
    "        Extract landmarks from video segment for given letter.\n",
    "        \n",
    "        Args:\n",
    "            letter: Letter to extract (A-Z)\n",
    "        \n",
    "        Returns:\n",
    "            List of landmark frames, each frame is a list of 21 (x,y,z) coordinates\n",
    "        \"\"\"\n",
    "        letter = letter.upper()\n",
    "        \n",
    "        if letter not in self.timestamps:\n",
    "            print(f\"No timestamp for letter: {letter}\")\n",
    "            return None\n",
    "        \n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # Get start and end times\n",
    "        start_time = self.timestamps[letter][\"start\"]\n",
    "        end_time = self.timestamps[letter][\"end\"]\n",
    "        \n",
    "        start_frame = int(start_time * fps)\n",
    "        end_frame = int(end_time * fps)\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        \n",
    "        landmarks_sequence = []\n",
    "        current_frame = start_frame\n",
    "        \n",
    "        print(f\"Extracting landmarks for {letter}...\")\n",
    "        \n",
    "        while current_frame < end_frame:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Process with MediaPipe\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hands.process(frame_rgb)\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                # Extract landmarks as list of (x, y, z)\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                frame_landmarks = []\n",
    "                \n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    frame_landmarks.append([landmark.x, landmark.y, landmark.z])\n",
    "                \n",
    "                landmarks_sequence.append(frame_landmarks)\n",
    "            else:\n",
    "                # No hand detected in this frame\n",
    "                # Use previous frame's landmarks if available, otherwise None\n",
    "                if landmarks_sequence:\n",
    "                    landmarks_sequence.append(landmarks_sequence[-1])\n",
    "                else:\n",
    "                    landmarks_sequence.append(None)\n",
    "            \n",
    "            current_frame += 1\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        # Filter out None frames\n",
    "        landmarks_sequence = [lm for lm in landmarks_sequence if lm is not None]\n",
    "        \n",
    "        print(f\"  Extracted {len(landmarks_sequence)} frames\")\n",
    "        \n",
    "        return landmarks_sequence\n",
    "    \n",
    "    def extract_all_letters(self, output_file='video_landmarks.pkl'):\n",
    "        \"\"\"\n",
    "        Extract landmarks for all letters and save to file.\n",
    "        \n",
    "        Args:\n",
    "            output_file: Path to save extracted landmarks\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping letters to landmark sequences\n",
    "        \"\"\"\n",
    "        all_landmarks = {}\n",
    "        \n",
    "        letters = sorted(self.timestamps.keys())\n",
    "        \n",
    "        for letter in letters:\n",
    "            landmarks = self.extract_landmarks_for_letter(letter)\n",
    "            if landmarks:\n",
    "                all_landmarks[letter] = landmarks\n",
    "        \n",
    "        # Save to file\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(all_landmarks, f)\n",
    "        \n",
    "        print(f\"\\nSaved all landmarks to {output_file}\")\n",
    "        print(f\"Total letters: {len(all_landmarks)}\")\n",
    "        \n",
    "        return all_landmarks\n",
    "    \n",
    "    def __del__(self):\n",
    "        if hasattr(self, 'hands'):\n",
    "            self.hands.close()\n",
    "\n",
    "# Extract landmarks from video\n",
    "# extractor = VideoLandmarkExtractor(output_file)\n",
    "# video_landmarks = extractor.extract_all_letters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eef84310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "\n",
    "class AnimatedSkeletonHintPlayer:\n",
    "    \"\"\"\n",
    "    Plays animated hand skeleton from extracted video landmarks.\n",
    "    Shows smooth, looping animation of the correct hand pose.\n",
    "    \"\"\"\n",
    "    def __init__(self, landmarks_file='video_landmarks.pkl'):\n",
    "        # Load extracted landmarks\n",
    "        with open(landmarks_file, 'rb') as f:\n",
    "            self.landmarks = pickle.load(f)\n",
    "        \n",
    "        # MediaPipe for drawing\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        \n",
    "        print(f\"Loaded landmarks for {len(self.landmarks)} letters\")\n",
    "    \n",
    "    def play_animated_hint(self, letter, window_name='Animated Hint', \n",
    "                          image_size=(640, 480), loop_count=3, playback_speed=1.0):\n",
    "        \"\"\"\n",
    "        Play animated skeleton for given letter.\n",
    "        \n",
    "        Args:\n",
    "            letter: Letter to show (A-Z)\n",
    "            window_name: OpenCV window name\n",
    "            image_size: Size of display window\n",
    "            loop_count: Number of times to loop animation\n",
    "            playback_speed: Speed multiplier (1.0 = normal, 2.0 = double speed)\n",
    "        \n",
    "        Returns:\n",
    "            True if played successfully\n",
    "        \"\"\"\n",
    "        letter = letter.upper()\n",
    "        \n",
    "        if letter not in self.landmarks:\n",
    "            print(f\"No landmarks for letter: {letter}\")\n",
    "            return False\n",
    "        \n",
    "        landmark_sequence = self.landmarks[letter]\n",
    "        \n",
    "        # Calculate frame delay\n",
    "        base_fps = 30  # Approximate original video FPS\n",
    "        frame_delay = int((1000 / base_fps) / playback_speed)\n",
    "        \n",
    "        for loop in range(loop_count):\n",
    "            for frame_landmarks in landmark_sequence:\n",
    "                # Create blank canvas\n",
    "                canvas = np.zeros((image_size[1], image_size[0], 3), dtype=np.uint8)\n",
    "                \n",
    "                # Convert landmarks to MediaPipe format\n",
    "                from mediapipe.framework.formats import landmark_pb2\n",
    "                \n",
    "                hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "                for x, y, z in frame_landmarks:\n",
    "                    landmark = hand_landmarks_proto.landmark.add()\n",
    "                    landmark.x = x\n",
    "                    landmark.y = y\n",
    "                    landmark.z = z\n",
    "                \n",
    "                # Draw on canvas\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    canvas,\n",
    "                    hand_landmarks_proto,\n",
    "                    self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    self.mp_drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "                \n",
    "                # Add text\n",
    "                cv2.putText(canvas, f\"Letter: {letter}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(canvas, \"Watch hand movement\", \n",
    "                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(canvas, f\"Loop {loop + 1}/{loop_count}\", \n",
    "                           (10, image_size[1] - 10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "                \n",
    "                cv2.imshow(window_name, canvas)\n",
    "                \n",
    "                # Allow early exit\n",
    "                if cv2.waitKey(frame_delay) & 0xFF == ord('q'):\n",
    "                    cv2.destroyWindow(window_name)\n",
    "                    return True\n",
    "        \n",
    "        cv2.destroyWindow(window_name)\n",
    "        return True\n",
    "\n",
    "# # Initialize\n",
    "# animated_hint_player = AnimatedSkeletonHintPlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e44b966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26 letter segments\n",
      "Extracting landmarks for A...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1768937698.100111       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extracted 23 frames\n",
      "Extracting landmarks for B...\n",
      "  Extracted 36 frames\n",
      "Extracting landmarks for C...\n",
      "  Extracted 33 frames\n",
      "Extracting landmarks for D...\n",
      "  Extracted 40 frames\n",
      "Extracting landmarks for E...\n",
      "  Extracted 31 frames\n",
      "Extracting landmarks for F...\n",
      "  Extracted 20 frames\n",
      "Extracting landmarks for G...\n",
      "  Extracted 36 frames\n",
      "Extracting landmarks for H...\n",
      "  Extracted 38 frames\n",
      "Extracting landmarks for I...\n",
      "  Extracted 36 frames\n",
      "Extracting landmarks for J...\n",
      "  Extracted 28 frames\n",
      "Extracting landmarks for K...\n",
      "  Extracted 67 frames\n",
      "Extracting landmarks for L...\n",
      "  Extracted 31 frames\n",
      "Extracting landmarks for M...\n",
      "  Extracted 28 frames\n",
      "Extracting landmarks for N...\n",
      "  Extracted 29 frames\n",
      "Extracting landmarks for O...\n",
      "  Extracted 40 frames\n",
      "Extracting landmarks for P...\n",
      "  Extracted 75 frames\n",
      "Extracting landmarks for Q...\n",
      "  Extracted 84 frames\n",
      "Extracting landmarks for R...\n",
      "  Extracted 74 frames\n",
      "Extracting landmarks for S...\n",
      "  Extracted 42 frames\n",
      "Extracting landmarks for T...\n",
      "  Extracted 30 frames\n",
      "Extracting landmarks for U...\n",
      "  Extracted 46 frames\n",
      "Extracting landmarks for V...\n",
      "  Extracted 27 frames\n",
      "Extracting landmarks for W...\n",
      "  Extracted 19 frames\n",
      "Extracting landmarks for X...\n",
      "  Extracted 36 frames\n",
      "Extracting landmarks for Y...\n",
      "  Extracted 27 frames\n",
      "Extracting landmarks for Z...\n",
      "  Extracted 45 frames\n",
      "\n",
      "Saved all landmarks to ../assets/video_landmarks.pkl\n",
      "Total letters: 26\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract landmarks from video (run once)\n",
    "# only need to run once!\n",
    "extractor = VideoLandmarkExtractor(video_path=video_path, timestamps_path=timestamps_path)\n",
    "video_landmarks = extractor.extract_all_letters(landmarks_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72f28ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded landmarks for 26 letters\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Test animated playback\n",
    "animated_hint_player = AnimatedSkeletonHintPlayer(landmarks_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "021963e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing animated hint for T...\n",
      "Playing animated hint for A...\n",
      "Playing animated hint for C...\n",
      "Playing animated hint for O...\n",
      "Playing animated hint for S...\n"
     ]
    }
   ],
   "source": [
    "# Test a few letters\n",
    "for letter in ['T', 'A', 'C', 'O', 'S']:\n",
    "    print(f\"Playing animated hint for {letter}...\")\n",
    "    animated_hint_player.play_animated_hint(letter, loop_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d51d9b",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingerspell-venv-af5b43d44a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
