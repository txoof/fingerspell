{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ce2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import joblib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "192919a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded 18893 frames\n"
     ]
    }
   ],
   "source": [
    "csv_path = Path('./data/dataset/ngt_dynamic_landmarks_18893.csv')\n",
    "if not csv_path.exists():\n",
    "    print(f\"Error: Dataset not found at {csv_path}\")\n",
    "    print(\"Please run dynamic data collection script first!\")\n",
    "    exit(1)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"\\n✓ Loaded {len(df)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dfbfcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Letters: ['H', 'J', 'U', 'X', 'Z']\n",
      "\n",
      "Samples per letter:\n",
      "letter\n",
      "H    30\n",
      "J    60\n",
      "U    60\n",
      "X    60\n",
      "Z    90\n",
      "Name: sample_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "letters = sorted(df['letter'].unique())\n",
    "samples_per_letter = df.groupby('letter')['sample_id'].nunique()\n",
    "print(f\"✓ Letters: {letters}\")\n",
    "print(f\"\\nSamples per letter:\")\n",
    "print(samples_per_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3965143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy: Pad/truncate all sequences to same length\n",
    "TARGET_FRAMES = 40  # Standard sequence length\n",
    "\n",
    "def normalize_landmarks(coords):\n",
    "    \"\"\"\n",
    "    Normalize a single frame of landmarks (21 x 3)\n",
    "    Same normalization as static model\n",
    "    \"\"\"\n",
    "    # Reshape to 21 landmarks x 3 coords\n",
    "    coords = coords.reshape(21, 3)\n",
    "    \n",
    "    # Center on wrist\n",
    "    wrist = coords[0]\n",
    "    coords = coords - wrist\n",
    "    \n",
    "    # Scale by hand size\n",
    "    hand_size = np.linalg.norm(coords[12] - coords[0])\n",
    "    if hand_size > 0:\n",
    "        coords = coords / hand_size\n",
    "    \n",
    "    return coords\n",
    "\n",
    "def process_sequence(group):\n",
    "    \"\"\"\n",
    "    Process one gesture sequence:\n",
    "    1. Normalize each frame\n",
    "    2. Pad or truncate to TARGET_FRAMES\n",
    "    3. Return flattened sequence\n",
    "    \"\"\"\n",
    "    # Sort frames in order\n",
    "    frames = group.sort_values('frame')\n",
    "    \n",
    "    # Get landmark columns (exclude letter, sample_id, frame)\n",
    "    landmark_cols = [col for col in frames.columns \n",
    "                     if col not in ['letter', 'sample_id', 'frame']]\n",
    "    \n",
    "    # Extract landmarks for each frame and normalize\n",
    "    normalized_frames = []\n",
    "    for _, row in frames.iterrows():\n",
    "        landmarks = row[landmark_cols].values  # 63 values\n",
    "        normalized = normalize_landmarks(landmarks)  # Normalize\n",
    "        normalized_frames.append(normalized.flatten())  # Back to 63\n",
    "    \n",
    "    normalized_frames = np.array(normalized_frames)\n",
    "    \n",
    "    # Pad or truncate to TARGET_FRAMES\n",
    "    num_frames = len(normalized_frames)\n",
    "    \n",
    "    if num_frames < TARGET_FRAMES:\n",
    "        # PAD: Repeat last frame\n",
    "        padding = np.repeat(normalized_frames[-1:], \n",
    "                           TARGET_FRAMES - num_frames, \n",
    "                           axis=0)\n",
    "        normalized_frames = np.vstack([normalized_frames, padding])\n",
    "        \n",
    "    elif num_frames > TARGET_FRAMES:\n",
    "        # TRUNCATE: Take first TARGET_FRAMES\n",
    "        normalized_frames = normalized_frames[:TARGET_FRAMES]\n",
    "    \n",
    "    # Flatten to single vector: (40 frames × 63 coords = 2520 features)\n",
    "    return normalized_frames.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e655a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed 300 sequences\n",
      "✓ Feature shape: (300, 2520)\n"
     ]
    }
   ],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "sample_info = []  # Track (letter, sample_id) for each processed sequence\n",
    "\n",
    "for (letter, sample_id), group in df.groupby(['letter', 'sample_id']):\n",
    "    sequence = process_sequence(group)\n",
    "    X_list.append(sequence)\n",
    "    y_list.append(letter)\n",
    "    sample_info.append((letter, sample_id))\n",
    "\n",
    "X = np.array(X_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(f\"✓ Processed {len(X)} sequences\")\n",
    "print(f\"✓ Feature shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ccfe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training gestures: 240\n",
      "✓ Testing gestures: 60\n",
      "\n",
      "✅ Verified: No gesture appears in both train and test\n",
      "   Train has 240 unique gestures\n",
      "   Test has 60 unique gestures\n"
     ]
    }
   ],
   "source": [
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "# Split per letter to maintain balance\n",
    "for letter in letters:\n",
    "    # Get all sample indices for this letter\n",
    "    letter_indices = [i for i, (l, _) in enumerate(sample_info) if l == letter]\n",
    "    \n",
    "    # Shuffle and split 80/20\n",
    "    np.random.seed(42)\n",
    "    shuffled = np.random.permutation(letter_indices)\n",
    "    \n",
    "    n_test = max(1, int(len(letter_indices) * 0.2))\n",
    "    \n",
    "    test_indices.extend(shuffled[:n_test])\n",
    "    train_indices.extend(shuffled[n_test:])\n",
    "\n",
    "# Create train/test sets\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "print(f\"✓ Training gestures: {len(X_train)}\")\n",
    "print(f\"✓ Testing gestures: {len(X_test)}\")\n",
    "\n",
    "# Verify no data leakage\n",
    "train_sample_ids = set([sample_info[i] for i in train_indices])\n",
    "test_sample_ids = set([sample_info[i] for i in test_indices])\n",
    "overlap = train_sample_ids & test_sample_ids\n",
    "\n",
    "if len(overlap) > 0:\n",
    "    print(f\"\\n❌ ERROR: {len(overlap)} samples in both train and test!\")\n",
    "    print(\"This should never happen!\")\n",
    "else:\n",
    "    print(f\"\\n✅ Verified: No gesture appears in both train and test\")\n",
    "    print(f\"   Train has {len(train_sample_ids)} unique gestures\")\n",
    "    print(f\"   Test has {len(test_sample_ids)} unique gestures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cbc06d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=50,         # Number of trees\n",
    "    max_depth=15,            # Max depth (slightly deeper for sequences)\n",
    "    min_samples_split=8,     # Min samples to split\n",
    "    min_samples_leaf=3,      # Min samples in leaf\n",
    "    max_features='sqrt',     # Random feature subset\n",
    "    class_weight='balanced', # Handle class imbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8812101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 100.00%\n",
      "Testing:  100.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = clf.score(X_train, y_train)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Training: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Testing:  {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eecc3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\dynamic_model_clf.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = Path('./models/dynamic_model_clf.pkl')\n",
    "model_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "joblib.dump(clf, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7be5aae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/dynamic_metadata.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = {\n",
    "    'target_frames': 40,\n",
    "    'letters': ['H', 'J', 'U', 'X', 'Z'],\n",
    "    'normalization': 'wrist_centered_scaled',\n",
    "    'feature_size': 2520,\n",
    "    'train_samples': 120,\n",
    "    'test_samples': 30,\n",
    "    'test_accuracy': 0.95\n",
    "}\n",
    "joblib.dump(metadata, './models/dynamic_metadata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caebafee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ngt_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
